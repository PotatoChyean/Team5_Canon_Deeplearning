"""
ëª¨ë¸ ì¶”ë¡  í†µí•© ë¡œì§ (ìµœì†Œ ìˆ˜ì • ë° í†µí•© ë²„ì „)
YOLO, ConditionalViT (CNN) ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ 7ë‹¨ê³„ ê·œì¹™ ê¸°ë°˜ Pass/Fail ë° ì œí’ˆ ëª¨ë¸ ë¶„ë¥˜
"""

import numpy as np
import torch
import time 
from typing import Dict, List, Optional, Tuple 
from PIL import Image, ImageDraw
from collections import Counter
import io
import os
import traceback
import base64
import cv2 # OpenCV ì„í¬íŠ¸ ìœ ì§€

# ì™¸ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸ ìœ ì§€
from .yolo_model import YOLOModel 
from .cnn_model import CNNModel

# ============================================================
# ì œí’ˆ ìŠ¤í™í…Œì´ë¸” ë° ë ˆì´ë¸” (V1 ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
# ... (PRODUCT_SPEC, LANG_LABEL, CLASS_NAMES, CLASS_MAP ìœ ì§€) ...
# ============================================================
PRODUCT_SPEC = {
    "FM2-V160-000": {"button": "ID",   "lang": "CN"},
    "FM2-V161-000": {"button": "Back", "lang": None},
    "FM2-V162-000": {"button": "Back", "lang": "EN"},
    "FM2-V163-000": {"button": "Back", "lang": "CN"},
    "FM2-V164-000": {"button": "Back", "lang": "KR"},
    "FM2-V165-000": {"button": "Back", "lang": "TW"},
    "FM2-V166-000": {"button": "ID",   "lang": "EN"},
    "FM2-V167-000": {"button": "Back", "lang": "JP"},
}

LANG_LABEL = ["CN", "EN", "JP", "KR", "TW"] 
CLASS_NAMES = ['Home', 'Back', 'ID', 'Stat', 'Monitor_Small', 'Monitor_Big', 'sticker', 'Text']
CLASS_MAP = { 0: 'Home', 1: 'Back', 2: 'ID', 3: 'Stat', 4: 'Monitor_Small', 
              5: 'Monitor_Big', 6: 'sticker', 7: 'Text'
}

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
yolo_model = None
cnn_model = None

# ============================================================
# ì œí’ˆ ëª¨ë¸ ìë™ ë¶„ë¥˜ í•¨ìˆ˜ (V1 ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
# ============================================================
def classify_model(found_back, found_id, text_langs):
    # (1) í…ìŠ¤íŠ¸ ì–¸ì–´ ê²°ì •
    if len(text_langs) == 0:
        lang = None
    else:
        lang = Counter(text_langs).most_common(1)[0][0] 

    # (2) Back/ID ê²°ì •
    if found_back and (not found_id):
        btn_type = "Back"  
    elif found_id and (not found_back):
        btn_type = "ID"
    else:
        return None, "Back/ID Mismatch" 

    # (3) í›„ë³´ ì œí’ˆ ì°¾ê¸°
    candidates = []
    for name, spec in PRODUCT_SPEC.items():
        if spec["lang"] == lang and spec["button"] == btn_type:
            candidates.append(name)

    if len(candidates) == 1:
        return candidates[0], None # ì„±ê³µ
    elif len(candidates) > 1:
        return None, "AmbiguousModel" # ì‹¤íŒ¨
    else:
        return None, "UnknownModel" # ì‹¤íŒ¨

# ============================================================
# NumPy íƒ€ì… ë³€í™˜ í•¨ìˆ˜ (V1 ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
# ============================================================
def convert_numpy_types(data):
    if isinstance(data, dict):
        return {k: convert_numpy_types(v) for k, v in data.items()}
    if isinstance(data, (list, tuple)):
        return [convert_numpy_types(i) for i in data]
    if isinstance(data, np.integer):
        return int(data)
    if isinstance(data, np.floating):
        return float(data)
    if isinstance(data, np.ndarray):
        return data.tolist()
    return data

# ============================================================
# ëª¨ë¸ ì´ˆê¸°í™” í•¨ìˆ˜ (V1 ì›ë³¸ ì½”ë“œì™€ ë™ì¼)
# ============================================================
def initialize_models(
    yolo_path: str = "models/YOLO.pt",
    cnn_path: str = "models/CNN_classifier.pt",
):
    """ëª¨ë¸ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    global yolo_model, cnn_model, DEVICE
    
    # YOLO ëª¨ë¸ ì´ˆê¸°í™”
    if yolo_model is None:
        try:
            yolo_model = YOLOModel(model_path=yolo_path) 
            DEVICE = yolo_model.device
        except Exception as e:
            print(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
    # CNN/Text ëª¨ë¸ ì´ˆê¸°í™”
    if cnn_model is None:
        try:
            cnn_model = CNNModel(model_path=cnn_path)
            print("CNN/Text ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
        except Exception as e:
            print(f"CNN/Text ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            cnn_model = None
            
    return yolo_model, cnn_model

# ============================================================
# ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ (ëª…ë„/ì¡°ë„ ì ìš© ë¡œì§ ì¶”ê°€)
# ============================================================
def analyze_image(image: np.ndarray, 
    # ğŸ’¡ [ìˆ˜ì •] ëª…ë„/ì¡°ë„ ì¸ìˆ˜ë¥¼ ë°›ë„ë¡ ì‹œê·¸ë‹ˆì²˜ ìˆ˜ì •
    brightness: float = 0.0, 
    exposure_gain: float = 1.0) -> Dict:
    """
    ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜: 7ë‹¨ê³„ ë³µí•© ê²€ì‚¬ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰ ë° ê²°ê³¼ JSON ë°˜í™˜
    """
    if yolo_model is None or cnn_model is None:
        initialize_models()
        if cnn_model is None:
            raise RuntimeError("CNN/Text ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    try:
        # TODO: ë””ë²„ê·¸
        print(f"[DEBUG] Brightness: {brightness}, Exposure: {exposure_gain}")
        
        # ì…ë ¥ ì´ë¯¸ì§€ë¥¼ RGB í¬ë§·ìœ¼ë¡œ ë³€í™˜
        pil_img_temp = Image.fromarray(image).convert("RGB")
        img_rgb = np.array(pil_img_temp) 
        pil_img = pil_img_temp
            
        original_img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
        
        # BGR í¬ë§·ìœ¼ë¡œ ë³€í™˜ (OpenCV ì²˜ë¦¬ë¥¼ ìœ„í•´)
        processed_img_bgr = original_img_bgr
        
        brightness_int = int(brightness)
        
        # ë””í´íŠ¸ ê°’ì´ ì•„ë‹ ë•Œ ë³´ì •
        if brightness_int != 0 or exposure_gain != 1.0:
             processed_img_bgr = cv2.convertScaleAbs(original_img_bgr, 
                                                 alpha=exposure_gain, 
                                                 beta=brightness_int)

        draw_img = processed_img_bgr.copy()
        
    
        # ëª¨ë¸ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ RGBë¡œ ì¬ë³€í™˜ (YOLO ëª¨ë¸ì´ RGBë¥¼ ê¸°ëŒ€í•œë‹¤ê³  ê°€ì •)
        # ëª…ë„/ì¡°ë„ ì ìš©ëœ BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜í•˜ì—¬ ëª¨ë¸ì— ì „ë‹¬
        img_rgb_corrected = cv2.cvtColor(processed_img_bgr, cv2.COLOR_BGR2RGB)
            
        # 1. YOLO ê°ì²´ ê²€ì¶œ
        yolo_results = yolo_model.detect(img_rgb_corrected) 
        
        # --- 2. YOLO ê²°ê³¼ í”Œë˜ê·¸ ë° CNN ë°ì´í„° ìˆ˜ì§‘ ---
        found_home = False
        found_stat = False
        found_monitor = False
        found_back = False
        found_id = False
        cnn_fail = False 
        
        cnn_results = []
        roi_pass_list = [] 
        text_langs = []
        yolo_detections = []
        confidence_scores = []
        cnn_button_status_map = {} 
        button_classes = ['Home', 'Back', 'ID', 'Stat']
        
        start_time_cnn_total = time.time() 

        for detection in yolo_results.get("detections", []):
            cls_name = detection["class"]
            bbox = detection["bbox"]
            conf = detection["confidence"]
            
            x1, y1, x2, y2 = map(int, bbox)
            if x1 >= x2 or y1 >= y2: continue
                
            # PIL ì´ë¯¸ì§€ëŠ” ì›ë³¸ (ìˆ˜ì • ì „)ì—ì„œ Cropì„ ìˆ˜í–‰
            # CNNModelì— ì „ë‹¬í•  ë•ŒëŠ” ëª…ë„ ì¡°ì ˆì´ í•„ìš”ì—†ë‹¤ê³  ê°€ì • (ëª¨ë¸ì´ Robustí•˜ë‹¤ê³  ê°€ì •)
            crop_pil = pil_img.crop((x1, y1, x2, y2)) 
            
            # --- í”Œë˜ê·¸ ì„¤ì • ---
            base_cls = cls_name.replace('Btn_', '')
            if base_cls == 'Home': found_home = True
            elif base_cls == 'Back': found_back = True
            elif base_cls == 'ID': found_id = True
            elif base_cls == 'Stat': found_stat = True
            elif cls_name in ['Monitor_Small', 'Monitor_Big', 'Monitor']: found_monitor = True

            # --- 3. CNN ìˆ˜í–‰ (ë²„íŠ¼ & í…ìŠ¤íŠ¸) ---
            current_status = None
            prob = 0.0
            
            if base_cls in button_classes:
                prob, is_pass = cnn_model.predict_roi(crop_pil.convert("L"), cls_name)
                current_status = "Pass" if is_pass else "Fail"
                
                roi_pass_list.append(is_pass) 
                if not is_pass:
                    cnn_fail = True
                
                # CNN ìƒíƒœ ë§µ ì—…ë°ì´íŠ¸
                if base_cls in cnn_button_status_map and cnn_button_status_map[base_cls] == "Fail":
                    pass
                else:
                    cnn_button_status_map[base_cls] = current_status
                
                cnn_results.append({
                    "class": base_cls,
                    "bbox": bbox,
                    "probability": round(prob, 4), 
                    "status": current_status
                })
                confidence_scores.append(prob * 100)

            elif base_cls == 'Text':
                prob, lang = cnn_model.predict_roi(crop_pil.convert("L"), cls_name)
                current_status = lang if isinstance(lang, str) else "Unknown"
                text_langs.append(current_status)
                confidence_scores.append(prob * 100)
            
            # --- 4. ì‹œê°í™” ë°ì´í„° ì¤€ë¹„ (ëª…ë„/ì¡°ë„ ì ìš©ëœ draw_imgì— ê·¸ë¦¬ê¸°) ---
            final_label = f"{base_cls} {current_status or ''}".strip()
            
            # ìƒ‰ìƒ ê²°ì • (V1 ì›ë³¸ ë¡œì§ ìœ ì§€)
            if current_status == 'Pass': color = (0, 255, 0) # Green (BGR)
            elif current_status == 'Fail': color = (0, 0, 255) # Red (BGR)
            else: color = (0, 200, 255) # Default (Cyan/Yellow) (BGR)

            # BBox ê·¸ë¦¬ê¸°
            cv2.rectangle(draw_img, (x1, y1), (x2, y2), color, 2)
            cv2.putText(draw_img, final_label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2, cv2.LINE_AA)
            cv2.putText(draw_img, final_label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1, cv2.LINE_AA)

            yolo_detections.append({
                "class": base_cls, "bbox": bbox, "confidence": round(conf, 4)
            })
            confidence_scores.append(conf * 100)
            
        time_cnn_total = time.time() - start_time_cnn_total
        print(f"[TIME CHECK] CNN ì´ ì¶”ë¡  ì‹œê°„: {time_cnn_total:.4f} ì´ˆ")

        # --- 5. 7ê°€ì§€ ê·œì¹™ ê¸°ë°˜ íŒì • ì‹œì‘ (V1 ì›ë³¸ ë¡œì§) ---
        prod, model_err = classify_model(found_back, found_id, text_langs)
        fails = []
        
        # ... (ì´í•˜ 7ë‹¨ê³„ íŒì • ë¡œì§ ìœ ì§€) ...
        # 1. í•„ìˆ˜ ìš”ì†Œ í™•ì¸ (Rule A)
        if not found_home: fails.append("Home Missing")
        if not found_stat: fails.append("Stat Missing")
        if not found_monitor: fails.append("Monitor Missing")

        # 2. Back XOR ID (Rule B)
        button_type = None
        current_id_back_status = "Fail"
        
        if found_back and found_id: 
            fails.append("Back and ID Both Present")
        elif (not found_back) and (not found_id):
            fails.append("Back/ID Missing")
        elif found_back:
            button_type = "Back"
        elif found_id:
            button_type = "ID"

        # 3. Rule C: CNN Failì„ ìµœì¢… Fail ëª©ë¡ì— ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€ 
        if button_type is not None:
            cnn_status = cnn_button_status_map.get(button_type, 'Fail')
        
            if cnn_status == "Pass" and prod is not None:
                current_id_back_status = "Pass"
                
            if cnn_status == "Fail":
                fails.append(f"{button_type} Button CNN Fail")
            if cnn_button_status_map.get('Stat') == "Fail":
                fails.append("Stat Button CNN Fail")
            
        # 4. ì „ì²´ CNN Fail í”Œë˜ê·¸ ê¸°ë°˜ Rule C ì¶”ê°€ (ë‹¤ë¥¸ ë²„íŠ¼ í¬í•¨)
        if cnn_fail: 
            if "Rule C: General Button Failure" not in fails:
                 pass 
                        
        # 5. Text ì¡°ê±´ (Rule D)
        text_count = len(text_langs)
        if not (text_count == 0 or text_count >= 3): fails.append(f"Text Count Invalid (N={text_count})")

        # 6. ëª¨ë¸ ë¶„ë¥˜ ê²°ê³¼ (Rule E)
        if prod is None: fails.append(model_err)
        
        # 7. ìµœì¢… íŒì •
        is_pass = (len(fails) == 0)
        final_status = "PASS" if is_pass else "FAIL" 
        reason = "; ".join(fails) if fails else None
        
        # --- 7. ìµœì¢… ê²°ê³¼ ì´ë¯¸ì§€ì— ìš”ì•½ ì •ë³´ ì¶”ê°€ (ëª…ë„/ì¡°ë„ ì ìš©ëœ draw_imgì— ê·¸ë¦¬ê¸°) ---
        
        # ì œí’ˆëª… í‘œì‹œ (V1 main ë¡œì§)
        title = prod if prod else "UNKNOWN"
        cv2.putText(draw_img, title, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2) # BGR: Cyan/Yellow

        # ìµœì¢… ìƒíƒœ í‘œì‹œ (V1 main ë¡œì§)
        if is_pass:
            status_color = (0, 255, 0) # Green
            cv2.putText(draw_img, "PASS", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.0, status_color, 3)
        else:
            status_color = (0, 0, 255) # Red
            cv2.putText(draw_img, "FAIL", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1.0, status_color, 3)
            
            # ì‹¤íŒ¨ ì‚¬ìœ  ëª©ë¡ ì¶œë ¥
            y = 140
            for r in fails:
                cv2.putText(draw_img, r, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)
                y += 30

        # --- 8. Base64 ì¸ì½”ë”© ë° ê²°ê³¼ ë°˜í™˜ ---
        
        _, buffer = cv2.imencode('.jpg', draw_img)
        annotated_image_str = base64.b64encode(buffer).decode('utf-8')

        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0

        final_result = {
            "status": final_status,
            "reason": reason,
            "confidence": round(avg_confidence, 2),
            "details": {
                # ... (ì¤‘ëµ) ...
                "annotated_image": annotated_image_str
            }
        }
        
        return convert_numpy_types(final_result)
        
    except Exception as e:
        traceback.print_exc()
        error_result = {
            "status": "FAIL",
            "reason": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}",
            "confidence": 0,
            "details": {}
        }
        return convert_numpy_types(error_result)


def analyze_frame(image: np.ndarray, 
    brightness: float = 0.0, 
    exposure_gain: float = 1.0) -> Dict: 
    """
    ì‹¤ì‹œê°„ í”„ë ˆì„ ë¶„ì„ (analyze_imageì— ì¸ìˆ˜ë¥¼ ì „ë‹¬)
    """
    return analyze_image(image, brightness=brightness, exposure_gain=exposure_gain)