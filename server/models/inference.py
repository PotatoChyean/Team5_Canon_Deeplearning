"""
ëª¨ë¸ ì¶”ë¡  í†µí•© ë¡œì§ (ìˆ˜ì • ë° í†µí•© ë²„ì „)
YOLO, ConditionalViT (CNN) ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ 7ë‹¨ê³„ ê·œì¹™ ê¸°ë°˜ Pass/Fail ë° ì œí’ˆ ëª¨ë¸ ë¶„ë¥˜
"""

import numpy as np
import torch
from typing import Dict, List, Optional
from PIL import Image
from collections import Counter
from ultralytics import YOLO
from torchvision import transforms
from transformers import ViTModel
import io
import os
import traceback

# ì™¸ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸ (ê°€ì •)
from models.yolo_model import YOLOModel
from models.cnn_model import CNNModel

# ê°€ì •ëœ ì™¸ë¶€ ëª¨ë“ˆ í´ë˜ìŠ¤
class ConditionalViT(torch.nn.Module):
    def __init__(self):
        super().__init__()
        # ì‹¤ì œ ëª¨ë¸ ì´ˆê¸°í™” ë¡œì§ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ë”ë¯¸)
        self.vit = ViTModel.from_pretrained("google/vit-base-patch16-224")
        self.head_btn = torch.nn.Linear(768, 2) # Pass/Fail (2 classes)
        self.head_txt = torch.nn.Linear(768, len(LANG_LABEL)) # Language (N classes)

    def forward(self, x, cond):
        x = self.vit(x).last_hidden_state[:, 0, :]
        if cond.item() == 0:
            return self.head_btn(x)
        elif cond.item() == 1:
            return self.head_txt(x)
        return x


# ============================================================
# ì œí’ˆ ìŠ¤í™í…Œì´ë¸” ë° ë ˆì´ë¸”
# ============================================================
PRODUCT_SPEC = {
    "FM2-V160-000": {"button": "ID",   "lang": "CN"},
    "FM2-V161-000": {"button": "STAT", "lang": None},
    "FM2-V162-000": {"button": "STAT", "lang": "EN"},
    "FM2-V163-000": {"button": "STAT", "lang": "CN"},
    "FM2-V164-000": {"button": "STAT", "lang": "KR"},
    "FM2-V165-000": {"button": "STAT", "lang": "TW"},
    "FM2-V166-000": {"button": "ID",   "lang": "EN"},
    "FM2-V167-000": {"button": "STAT", "lang": "JP"},
}

LANG_LABEL = ["CN", "EN", "JP", "KR", "TW"]

# YOLO í´ë˜ìŠ¤ ì´ë¦„ (ì´ì „ ê·œì¹™ì— ë§ê²Œ ì¬ì •ì˜)
# 0: Home, 1: Back, 2: ID, 3: Stat, 4: Monitor, 5: Text
CLASS_NAMES = ['Home', 'Back', 'ID', 'Stat', 'Monitor', 'Text', 'Monitor_Small', 'Monitor_Big', 'sticker']
CLASS_MAP = { 
    0: 'Home', 1: 'Back', 2: 'ID', 3: 'Stat', 4: 'Monitor', 5: 'Text', 
    6: 'Monitor_Small', 7: 'Monitor_Big', 8: 'sticker'
}

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
yolo_model = None
cnn_model = None
transform = None
DEVICE = "cpu"

# ============================================================
# ì œí’ˆ ëª¨ë¸ ìë™ ë¶„ë¥˜ í•¨ìˆ˜
# ============================================================
def classify_model(found_back, found_id, text_langs):
    
    # (1) í…ìŠ¤íŠ¸ ì–¸ì–´ ê²°ì •
    if len(text_langs) == 0:
        lang = None
    else:
        # N >= 3ì¸ ê²½ìš° ë‹¤ìˆ˜ê²° (majority)
        lang = Counter(text_langs).most_common(1)[0][0] 

    # (2) Back/ID ê²°ì •
    if found_back and (not found_id):
        btn_type = "STAT"  # Back â†’ STAT ëª¨ë¸êµ°
    elif found_id and (not found_back):
        btn_type = "ID"
    else:
        # ì´ ì—ëŸ¬ëŠ” analyze_imageì˜ yolo_xor_okì—ì„œ ì´ë¯¸ ê±¸ëŸ¬ì§€ì§€ë§Œ, ëª…ì‹œì ìœ¼ë¡œ ë°˜í™˜
        return None, "Back/ID Mismatch (XOR Fail)" 

    # (3) í›„ë³´ ì œí’ˆ ì°¾ê¸°
    candidates = []
    for name, spec in PRODUCT_SPEC.items():
        if spec["lang"] == lang and spec["button"] == btn_type:
            candidates.append(name)

    if len(candidates) == 1:
        return candidates[0], None # ì„±ê³µ
    elif len(candidates) > 1:
        return None, "AmbiguousModel" # ì‹¤íŒ¨
    else:
        return None, "UnknownModel" # ì‹¤íŒ¨

# ============================================================
# NumPy íƒ€ì… ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
# ============================================================
def convert_numpy_types(data):
    """
    ë¶„ì„ ê²°ê³¼ì— í¬í•¨ëœ NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ì¬ê·€ì ìœ¼ë¡œ ë³€í™˜
    """
    if isinstance(data, dict):
        return {k: convert_numpy_types(v) for k, v in data.items()}
    if isinstance(data, (list, tuple)):
        return [convert_numpy_types(i) for i in data]
    if isinstance(data, np.integer):
        return int(data)
    if isinstance(data, np.floating):
        return float(data)
    if isinstance(data, np.ndarray):
        return data.tolist()
    return data

# ============================================================
# ëª¨ë¸ ì´ˆê¸°í™” í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
# ============================================================
def initialize_models(
    yolo_path: str = "models/YOLO.pt",
    cnn_path: str = "models/CNN_classifier.pt",
):
    """ëª¨ë¸ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    global yolo_model, cnn_model, transform, DEVICE
    
    # YOLO ëª¨ë¸ ì´ˆê¸°í™” (YOLOModelì€ ì™¸ë¶€ ëª¨ë“ˆ ê°€ì •)
    if yolo_model is None:
        yolo_model = YOLOModel(model_path=yolo_path)

    # CNN/Text ëª¨ë¸ ì´ˆê¸°í™” (ì¶”ê°€)
    if cnn_model is None:
        try:
            DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"Using device: {DEVICE}")
            
            cnn_model = ConditionalViT() 
            cnn_model.load_state_dict(torch.load(cnn_path, map_location=DEVICE))
            cnn_model.eval()
            cnn_model = cnn_model.to(DEVICE)

            # ì´ë¯¸ì§€ ë³€í™˜ ì •ì˜
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])
            print("CNN/Text ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
        except Exception as e:
            print(f"CNN/Text ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            cnn_model = None
            
    return yolo_model, cnn_model

# ============================================================
# ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜ (ìµœì¢… ìˆ˜ì •)
# ============================================================
def analyze_image(image: np.ndarray) -> Dict:
    """
    ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜: 7ë‹¨ê³„ ë³µí•© ê²€ì‚¬ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰ ë° ê²°ê³¼ êµ¬ì¡° ë³€ê²½ ë°˜ì˜
    """
    # ëª¨ë¸ ì´ˆê¸°í™” í™•ì¸
    if yolo_model is None or cnn_model is None or transform is None:
        initialize_models()
        if cnn_model is None:
            raise RuntimeError("CNN/Text ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ˆê¸°í™” ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    try:
        # ì´ë¯¸ì§€ë¥¼ PIL Imageë¡œ ë³€í™˜ (RGBë¡œ ë³€í™˜)
        if len(image.shape) == 3 and image.shape[2] == 3:
            pil_img = Image.fromarray(image).convert("RGB")
        else:
            pil_img = Image.fromarray(image).convert("RGB") 

        # 1. YOLO ê°ì²´ ê²€ì¶œ
        yolo_results = yolo_model.detect(image) 
        detected_classes_raw = [d["class"] for d in yolo_results.get("detections", [])]
        
        # --- 2. YOLO ê²°ê³¼ í”Œë˜ê·¸ ì´ˆê¸°í™” ë° CNN ë°ì´í„° ìˆ˜ì§‘ ---
        found_home = False
        found_stat = False
        found_monitor = False
        found_back = False
        found_id = False

        cnn_results = []
        roi_pass_list = [] # ë²„íŠ¼ CNN PASS/FAIL ê²°ê³¼ë§Œ ì €ì¥
        text_langs = []
        
        button_classes = ['Home', 'Back', 'ID', 'Stat', 'Btn_Home', 'Btn_Back', 'Btn_ID', 'Btn_Stat']
        
        for detection in yolo_results.get("detections", []):
            cls_name = detection["class"]
            bbox = detection["bbox"]
            crop_pil = pil_img.crop((bbox[0], bbox[1], bbox[2], bbox[3])) 
            
            # í”Œë˜ê·¸ ì„¤ì •
            if cls_name in ['Home', 'Btn_Home']: found_home = True
            elif cls_name in ['Back', 'Btn_Back']: found_back = True
            elif cls_name in ['ID', 'Btn_ID']: found_id = True
            elif cls_name in ['Stat', 'Btn_Stat']: found_stat = True
            elif cls_name == 'Monitor': found_monitor = True
            elif cls_name in ['Monitor_Small', 'Monitor_Big']: found_monitor = True
            
            # --- 3. CNN ìˆ˜í–‰ (ë²„íŠ¼ & í…ìŠ¤íŠ¸) ---
            
            if cls_name in button_classes:
                # CNN head_btn (cond = 0): Pass/Fail ë¶„ë¥˜
                cond = torch.tensor([0]).to(DEVICE)
                with torch.no_grad():
                    t = transform(crop_pil).unsqueeze(0).to(DEVICE)
                    out = cnn_model(t, cond)[0]
                
                prob_pass = torch.softmax(out[:2], dim=0)[0].item() # Pass í™•ë¥ 
                is_pass = (torch.argmax(out[:2]).item() == 0) # 0ì´ Pass
                
                roi_pass_list.append(is_pass) # ëª¨ë“  íƒì§€ëœ ë²„íŠ¼ì— ëŒ€í•´ í’ˆì§ˆ ì²´í¬
                
                cnn_results.append({
                    "class": cls_name,
                    "bbox": bbox,
                    "probability": round(prob_pass, 4), 
                    "status": "Pass" if is_pass else "Fail"
                })

            elif cls_name == 'Text':
                # CNN head_txt (cond = 1): ì–¸ì–´ ë¶„ë¥˜
                cond = torch.tensor([1]).to(DEVICE)
                with torch.no_grad():
                    t = transform(crop_pil).unsqueeze(0).to(DEVICE)
                    out = cnn_model(t, cond)[0]
                
                lang_idx = torch.argmax(out).item()
                lang = LANG_LABEL[lang_idx]
                prob_lang = torch.softmax(out, dim=0)[lang_idx].item()
                
                text_langs.append(lang)
                
                cnn_results.append({
                    "class": cls_name,
                    "bbox": bbox,
                    "probability": round(prob_lang, 4), 
                    "status": "OK", 
                    "lang": lang
                })

        # --- 4. 7ê°€ì§€ ê·œì¹™ ê¸°ë°˜ íŒì • ì‹œì‘ ---
        
        # Rule A: YOLO ì¡´ì¬ ì¡°ê±´ (Home, Stat, Monitor)
        yolo_presence_ok = found_home and found_stat and found_monitor
        
        # Rule B: Back XOR ID ì¡°ê±´
        yolo_xor_ok = found_back ^ found_id
        
        # Rule C: ë²„íŠ¼ CNN PASS ì¡°ê±´ (ëª¨ë“  íƒì§€ëœ ë²„íŠ¼)
        cnn_ok = all(roi_pass_list) if roi_pass_list else False

        # Rule D: í…ìŠ¤íŠ¸ ê°œìˆ˜ ì¡°ê±´ (N=0 ë˜ëŠ” N>=3)
        text_count = len(text_langs)
        text_ok = (text_count == 0) or (text_count >= 3)

        # Rule E: ì œí’ˆ ëª¨ë¸ ë¶„ë¥˜ ì„±ê³µ
        detected_prod, model_err = classify_model(found_back, found_id, text_langs)
        model_ok = (detected_prod is not None)
        
        # --- 5. ìµœì¢… íŒì • ---
        final_pass = yolo_presence_ok and yolo_xor_ok and cnn_ok and text_ok and model_ok
        final_status = "PASS" if final_pass else "FAIL" 
        
        # --- 6. Fail ì‚¬ìœ  ìˆ˜ì§‘ ---
        reasons = []
        if not yolo_presence_ok: reasons.append("í•„ìˆ˜ ê°ì²´ ë¯¸ê²€ì¶œ (Home/Stat/Monitor)")
        if not yolo_xor_ok: reasons.append("Back/ID ì¡°ê±´ ë¶ˆë§Œì¡± (XOR ì‹¤íŒ¨)")
        if not cnn_ok: reasons.append("ë²„íŠ¼ CNN ê²€ì¦ ì‹¤íŒ¨")
        if not text_ok: reasons.append(f"í…ìŠ¤íŠ¸ ê°œìˆ˜ ë¶ˆë§Œì¡± (N={text_count})")
        
        if not model_ok: reasons.append(model_err) 

        reason = "; ".join(reasons) if reasons else None
        
        # ğŸš¨ [í•µì‹¬ ìˆ˜ì •]: í”„ë¡ íŠ¸ì—”ë“œ ìš”ì²­ì— ë§ê²Œ ì„¸ë¶„í™”ëœ 4ê°€ì§€ ìƒíƒœ ì •ì˜
        # 1. HOME ìƒíƒœ: HOME ë²„íŠ¼ ê²€ì¶œ (YOLO) & ì „ì²´ ë²„íŠ¼ í’ˆì§ˆ ê²€ì‚¬ (CNN) í†µê³¼
        home_status = "Pass" if found_home and cnn_ok else "Fail"
        
        # 2. ID/BACK ìƒíƒœ: ID/BACK XOR ì¡°ê±´ (YOLO) & ì „ì²´ ë²„íŠ¼ í’ˆì§ˆ ê²€ì‚¬ (CNN) í†µê³¼
        id_back_status = "Pass" if yolo_xor_ok and cnn_ok else "Fail"
        
        # 3. STATUS ìƒíƒœ: STAT ë²„íŠ¼ ê²€ì¶œ (YOLO) & ì „ì²´ ë²„íŠ¼ í’ˆì§ˆ ê²€ì‚¬ (CNN) í†µê³¼
        status_status = "Pass" if found_stat and cnn_ok else "Fail"
        
        # 4. SCREEN ìƒíƒœ: Monitor ê²€ì¶œ (YOLO)
        screen_status = "Pass" if found_monitor else "Fail"
        
        # --- 7. ì‹ ë¢°ë„ ê³„ì‚° ë° ê²°ê³¼ êµ¬ì„± ---
        confidence_scores = []
        for detection in yolo_results.get("detections", []):
            confidence_scores.append(detection.get("confidence", 0) * 100)
        for cnn_result in cnn_results:
            confidence_scores.append(cnn_result.get("probability", 0) * 100)
        
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
        
        final_result = {
            "status": final_status,
            "reason": reason,
            "confidence": round(avg_confidence, 2),
            "details": {
                "product_model": detected_prod,
                "language": Counter(text_langs).most_common(1)[0][0] if text_langs else None,
                
                # ğŸš¨ [ìµœì¢… ë°˜ì˜] í”„ë¡ íŠ¸ì—”ë“œ ìš”ì²­ì— ë”°ë¼ 4ê°€ì§€ ê°œë³„ ìƒíƒœë¡œ ëŒ€ì²´ (ê¸°ì¡´ yolo_status, cnn_status, ocr_status ì œê±°)
                "home_status": home_status,
                "id_back_status": id_back_status,
                "status_status": status_status,
                "screen_status": screen_status,
                
                "model_status": "Pass" if model_ok else "Fail",
                "text_count": text_count,
                "yolo_detections": yolo_results.get("detections", []),
                "cnn_results": cnn_results, 
                "detected_classes": detected_classes_raw
            }
        }
        return convert_numpy_types(final_result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        error_result = {
            "status": "FAIL",
            "reason": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {str(e)}",
            "confidence": 0,
            "details": {}
        }
        return convert_numpy_types(error_result)


def analyze_frame(image: np.ndarray) -> Dict:
    """
    ì‹¤ì‹œê°„ í”„ë ˆì„ ë¶„ì„ (analyze_imageì™€ ë™ì¼)
    """
    return analyze_image(image)